<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Jeff Jacobs" />


<title>Sentiment Analysis in R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">CU Text-as-Data Workshop</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Workshop Sessions <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="01_Introduction_to_R.html">Week 1: Intro to R</a></li>
            <li><a href="02_Web_Scraping.html">Week 2: Web Scraping</a></li>
            <li><a href="03_Frequency_Analysis.html">Week 3: Frequency Analysis</a></li>
            <li><a href="04_Topic_Modeling_ggplot2.html">Week 4: Topic Modeling and Visualization</a></li>
            <li role="separator" class="divider"></li>
            <li><a href="05_Named_Entity_Recognition.html">Bonus: Named Entity Recognition</a></li>
            <li><a href="06_Machine_Learning.html">Bonus: Machine Learning with Text</a></li>
            <li><a href="07_Sentiment_Analysis.html">Bonus: Sentiment Analysis</a></li>
            <li class="disabled"><a href="08_Stylometry">Bonus: Stylometry</a></li>
            <li class="disabled"><a href="09_Word_Embeddings.html">Bonus: Word Embeddings</a></li>
          </ul>
        </li>
        <li>
          <a href="TAD_Resource_Extravaganza.html">Resources</a>
        </li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li><a href="http://textlab.econ.columbia.edu/">CU TextLab</a></li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Sentiment Analysis in R</h1>
<h4 class="author"><em>Jeff Jacobs</em></h4>
<h4 class="date"><em>2/7/2019</em></h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Sentiment analysis is a new-ish technique within Natural Language Processing, and one which often makes anyone outside of Computer Science cringe profusely, due to the simplicity of early models. Actually, to this day, unless you’re working somewhat close to the “cutting edge” of sentiment analysis, the “off-the-shelf” models are pretty cringey, in that they usually just give a score from “extremely bad” to “extremely good” rather than trying to capture the nuances of emotional valence.</p>
<p>In these researchers’ defense, though, this simplistic scale makes a lot of sense given the problems that were initially undertaken by the field. For example, some of the earliest work was done on <a href="http://ai.stanford.edu/~amaas/data/sentiment/">IMDB movie reviews</a>, where users provide both a textual review <em>and</em> a score from 1 to 5 stars. The researchers then simply aimed to predict, using only the text, what the user gave the movie, hence the 1 to 5 “bad” to “good” scale.</p>
<p>It’s also not so bad for social science researchers, either (as compared to, say, psychologists), since many of our surveys still ask questions like “How do you feel about Trump’s decision to move the US embassy in Israel to Jerusalem”? And prompt the user to pick a discrete Likert-scale rating from “Strongly Disagree” to “Strongly Agree”. Thus in this tutorial we’ll be using this type of simplified single-dimensional sentiment analysis model, but just know that you can dig deeper and find more nuanced multi-dimensional models.</p>
</div>
<div id="the-libraries" class="section level1">
<h1>The Libraries</h1>
<p>We’ll be working with a few different sentiment analysis libraries here, each of which are suited to different research settings: first, we’ll look at <code>sentimentr</code>, an R library that you can quickly download using <code>install.packages(&quot;sentimentr&quot;)</code> and start analyzing sentences immediately. This library probably has the simplest learning curve of the three. Then we’ll switch to the <a href="https://cloud.google.com/natural-language/">Google Cloud Natural Language API</a>, a far more powerful (but potentially costly) library which can process thousands of sentences per second. Hopefully this will make the tutorial useful for you, since if your project’s <span class="math inline">\(N\)</span> is in (say) the hundreds you can just use <code>sentimentr</code> on your local machine, and if its <span class="math inline">\(N\)</span> is in the thousands or millions you can instead opt to use the Google API. Finally, we’ll carry out a more realistic sentiment analysis project by using the <code>syuzhet</code> library, which (among other features) allows you to measure sentiment on multiple dimensions – as opposed to the “good” vs. “bad” dimension measured by <code>sentimentr</code> and the Google API – and has a simple interface allowing you to easily plot sentiment over time.</p>
</div>
<div id="quick-demos" class="section level1">
<h1>Quick Demos</h1>
<div id="sentimentr-demo" class="section level2">
<h2><code>sentimentr</code> Demo</h2>
<p>Before we dive in, we can do two quick demos illustrating the features of both libraries. Let’s start with <code>sentimentr</code> by loading the library into working memory using the <code>library()</code> function:</p>
<pre class="r"><code>library(sentimentr)</code></pre>
<p>Now, to see how sentiment analysis works at the most basic level, let’s give it two sentences – the first one unambiguously expressing a negative sentiment, the other a positive sentiment:</p>
<pre class="r"><code>bolsonaro_lula &lt;- &quot;Bolsonaro is scary, dude. Lula is cool, though.&quot;
sentiment(bolsonaro_lula)</code></pre>
<pre><code>##    element_id sentence_id word_count sentiment
## 1:          1           1          4    -0.250
## 2:          1           2          4     0.375</code></pre>
<p>Cool, so that worked as expected. To understand why, we can use <code>sentimentr</code>’s <code>extract_sentiment_terms()</code> to see specifically which terms it picked up as particularly negative and which it picked up as positive:</p>
<pre class="r"><code>extract_sentiment_terms(bolsonaro_lula)</code></pre>
<pre><code>##    element_id sentence_id negative positive
## 1:          1           1    scary         
## 2:          1           2              cool</code></pre>
<p>Now let’s try a sentence containing both a positive and a negative sentiment, but with the <em>same</em> magnitude, so that the sentence essentially has a neutral sentiment when treated as a whole (i.e., a sentence where the negative and positive sentiments “cancel out”):</p>
<pre class="r"><code>lenin &lt;- &quot;Lenin had both good and bad qualities.&quot;
sentiment(lenin)</code></pre>
<pre><code>##    element_id sentence_id word_count sentiment
## 1:          1           1          7         0</code></pre>
<p>Nice! It was able to recognize the “magnitude” of the two contrasting parts of the sentence, so that in the end the sentence comes out neutral. We can again take a look at the specific terms to understand why:</p>
<pre class="r"><code>extract_sentiment_terms(lenin)</code></pre>
<pre><code>##    element_id sentence_id negative positive
## 1:          1           1      bad     good</code></pre>
<p>Finally, let’s try a case where the sentence has both positive and negative sentiment, but with <em>asymmetric</em> magnitudes, such that the negative sentiment is far more extreme than the positive:</p>
<pre class="r"><code>carter_sent &lt;- &quot;Jimmy Carter&#39;s foreign policy was good, but his domestic policy was terrible.&quot;
sentiment(carter_sent)</code></pre>
<pre><code>##    element_id sentence_id word_count  sentiment
## 1:          1           1         12 -0.5051815</code></pre>
<pre class="r"><code>extract_sentiment_terms(carter_sent)</code></pre>
<pre><code>##    element_id sentence_id                  negative positive
## 1:          1           1 foreign,domestic,terrible     good</code></pre>
<p>So here we have our first weird result: the sentiment score is “correct”, in that the sentence is overall negative due to “terrible” having a greater negative magnitude than “good”’s positive magnitude, but this score is probably skewed by the fact that <code>sentimentr</code> considers both “foreign” and “domestic” to be negative words, in addition to “terrible”. So let’s see what happens if we force it to just compare “good” and “terrible”:</p>
<pre class="r"><code>trudeau &lt;- &quot;Justin Trudeau might look good, but his policies are terrible.&quot;
trudeau_result &lt;- sentiment(trudeau)
trudeau_result</code></pre>
<pre><code>##    element_id sentence_id word_count  sentiment
## 1:          1           1         10 -0.2964635</code></pre>
<pre class="r"><code>extract_sentiment_terms(trudeau)</code></pre>
<pre><code>##    element_id sentence_id negative positive
## 1:          1           1 terrible     good</code></pre>
<p>And thus we obtain the expected behavior: it recognizes that “terrible” is more negative than “good” is positive, so that the overall score comes out negative. These prior two examples are really just to show you that you should always be careful about the sentiment scores, and try to “dig” into them as much as possible, since they might be driven by extraneous factors like the valences ascribed to “domestic” and “foreign” by <code>sentimentr</code>.</p>
</div>
<div id="google-cloud-api-demo" class="section level2">
<h2>Google Cloud API Demo</h2>
<p>Now let’s check out a Google Cloud Natural Language API example. Although below we’ll use R to make calls to this API, for now let’s just copy and paste those same sentences into Google’s <a href="https://cloud.google.com/natural-language/">online demo</a> (it should appear directly under the “Powerful Text Analysis” section, though sometimes it takes a while to load): <img src="Sentiment_Analysis_files/bolsonaro.png" /></p>
<div class="figure">
<img src="Sentiment_Analysis_files/lenin.png" />

</div>
<div class="figure">
<img src="Sentiment_Analysis_files/carter.png" />

</div>
<p><img src="Sentiment_Analysis_files/trudeau.png" /> To be honest I’m a bit taken aback by how un-intuitive these scores are, but again for projects with a high number of documents, it may be the best choice regardless.</p>
</div>
<div id="syzhet-demo" class="section level2">
<h2><code>syzhet</code> Demo</h2>
<pre class="r"><code>library(syuzhet)
dead_prez &lt;- c(&quot;I want to be free to live, able to have what I need to live.&quot;, &quot;Bring the power back to the streets, where the people live.&quot;,&quot; We&#39;re sick of working for crumbs and filling up the prisons, dying over money and relying on religion for help.&quot;)

get_sentiment(dead_prez)</code></pre>
<pre><code>## [1]  0.5  0.0 -0.4</code></pre>
<pre class="r"><code>get_nrc_sentiment(dead_prez)</code></pre>
<pre><code>##   anger anticipation disgust fear joy sadness surprise trust negative
## 1     0            0       0    0   0       0        0     0        0
## 2     0            0       0    0   0       0        0     0        0
## 3     2            1       2    1   1       2        1     2        2
##   positive
## 1        0
## 2        0
## 3        2</code></pre>
</div>
</div>
<div id="sentimentr" class="section level1">
<h1><code>sentimentr</code></h1>
<p>Although the <code>sentimentr</code> demo above is interesting, you’re (hopefully) not usually going to be working with text that you manually type into R. So here we look at how to load a <em>corpus</em> of texts and obtain sentiment information for each one.</p>
</div>
<div id="googlelanguager" class="section level1">
<h1><code>GoogleLanguageR</code></h1>
<p>To interface with the Google Language API programmatically, we will use the extremely convenient <a href="https://github.com/ropensci/googleLanguageR"><code>GoogleLanguageR</code> package</a>.</p>
<pre class="r"><code>library(googleLanguageR)
gl_auth(&quot;../gcloud/nlp_api_teaching.json&quot;)</code></pre>
<pre class="r"><code>texts &lt;- c(&quot;The Tuskegee Study of Untreated Syphilis in the Negro Male was an infamous and unethical clinical study conducted between 1932 and 1972 by the U.S. Public Health Service. The purpose of this study was to observe the natural history of untreated syphilis; the African-American men in the study were told they were receiving free health care from the United States government.&quot;,&quot;Investigators enrolled in the study a total of 600 impoverished, African-American sharecroppers from Macon County, Alabama. The men were told that the study was only going to last six months, but it actually lasted 40 years. After funding for treatment was lost, the study was continued without informing the men that they would never be treated. None of the men were ever told that they had the disease, and none were treated with penicillin even after the antibiotic was proven to successfully treat syphilis.&quot;)
nlp_result &lt;- gl_nlp(texts)</code></pre>
<pre><code>## 2019-02-20 17:25:28 -- annotateText: 374 characters</code></pre>
<pre><code>## 2019-02-20 17:25:29 -- annotateText: 511 characters</code></pre>
<pre class="r"><code>attributes(nlp_result)</code></pre>
<pre><code>## $names
## [1] &quot;sentences&quot;         &quot;tokens&quot;            &quot;entities&quot;         
## [4] &quot;language&quot;          &quot;text&quot;              &quot;documentSentiment&quot;
## [7] &quot;classifyText&quot;</code></pre>
<p>So we see that, broadly speaking, we can get information about the sentences, tokens (roughly corresponding to words), entities (people, places, proper nouns), language detection, text (the original text we sent to the API), document sentiment, and categorical classification of the text.</p>
<pre class="r"><code>nlp_result$sentences</code></pre>
<pre><code>## [[1]]
##                                                                                                                                                                                                       content
## 1                                  The Tuskegee Study of Untreated Syphilis in the Negro Male was an infamous and unethical clinical study conducted between 1932 and 1972 by the U.S. Public Health Service.
## 2 The purpose of this study was to observe the natural history of untreated syphilis; the African-American men in the study were told they were receiving free health care from the United States government.
##   beginOffset magnitude score
## 1           0       0.8  -0.8
## 2         171       0.0   0.0
## 
## [[2]]
##                                                                                                                                                                content
## 1                                          Investigators enrolled in the study a total of 600 impoverished, African-American sharecroppers from Macon County, Alabama.
## 2                                                                 The men were told that the study was only going to last six months, but it actually lasted 40 years.
## 3                                            After funding for treatment was lost, the study was continued without informing the men that they would never be treated.
## 4 None of the men were ever told that they had the disease, and none were treated with penicillin even after the antibiotic was proven to successfully treat syphilis.
##   beginOffset magnitude score
## 1           0       0.0   0.0
## 2         124       0.1  -0.1
## 3         225       0.8  -0.8
## 4         347       0.2  -0.2</code></pre>
<pre class="r"><code>nlp_result$documentSentiment</code></pre>
<pre><code>## # A tibble: 2 x 2
##   magnitude score
##       &lt;dbl&gt; &lt;dbl&gt;
## 1       0.8  -0.4
## 2       1.3  -0.2</code></pre>
<pre class="r"><code>cols &lt;- c(&quot;name&quot;,&quot;type&quot;,&quot;salience&quot;,&quot;score&quot;,&quot;magnitude&quot;)
nlp_result$entities[[1]][cols]</code></pre>
<pre><code>## # A tibble: 13 x 5
##    name                                 type      salience score magnitude
##    &lt;chr&gt;                                &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
##  1 African-American                     PERSON     0.00426   0         0  
##  2 government                           ORGANIZA…  0.0115    0         0  
##  3 health care                          OTHER      0.0126    0         0  
##  4 history                              OTHER      0.0216    0         0  
##  5 men                                  PERSON     0.0559    0         0  
##  6 purpose                              OTHER      0.0265    0         0  
##  7 study                                &lt;NA&gt;      NA        NA        NA  
##  8 study                                &lt;NA&gt;      NA        NA        NA  
##  9 study                                &lt;NA&gt;      NA        NA        NA  
## 10 syphilis                             OTHER      0.00819   0         0  
## 11 Tuskegee Study of Untreated Syphili… OTHER      0.824     0         0  
## 12 U.S. Public Health Service           ORGANIZA…  0.0289   -0.5       0.5
## 13 United States                        LOCATION   0.00679   0         0</code></pre>
<pre class="r"><code>nlp_result$entities[[2]][cols]</code></pre>
<pre><code>## # A tibble: 31 x 5
##    name             type     salience score magnitude
##    &lt;chr&gt;            &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
##  1 African-American PERSON    0.0311    0         0  
##  2 Alabama          LOCATION  0.0311    0         0  
##  3 antibiotic       OTHER     0.00835   0.7       0.7
##  4 disease          OTHER     0.0119    0         0  
##  5 Investigators    PERSON    0.131    -0.2       0.2
##  6 Macon County     LOCATION  0.0311    0         0  
##  7 men              PERSON    0.0557   -0.3       0.7
##  8 men              PERSON    0.0557   -0.3       0.7
##  9 men              PERSON    0.0557   -0.3       0.7
## 10 men              PERSON    0.0197    0.5       0.5
## # ... with 21 more rows</code></pre>
<pre class="r"><code>nlp_result$classifyText</code></pre>
<pre><code>## # A tibble: 2 x 2
##   name                                          confidence
##   &lt;chr&gt;                                              &lt;dbl&gt;
## 1 /Health/Health Conditions/Infectious Diseases       0.88
## 2 /Health/Reproductive Health                         0.77</code></pre>
</div>
<div id="syuzhet" class="section level1">
<h1><code>syuzhet</code></h1>
<p>Finally, let’s do something that resembles a project you might actually carry out for actual social science research! For a separate project I (grudgingly) scraped every Donald Trump tweet, from the beginning of his Twitter account to the present day (updated as needed… I might have an API set up to automatically do this… or I might not… You’ll have to ask to find out… More ellipses…), giving 36,724 in total, as of February 8th, 2019. Let’s <a href="https://cran.r-project.org/web/packages/syuzhet/vignettes/syuzhet-vignette.html">use <code>syuzhet</code></a> to see how Trump’s mood has fluctuated over the years:</p>
<pre class="r"><code>trump_df &lt;- read_csv(&quot;Sentiment_Analysis_files/trump_tweets.csv&quot;)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   created_at = col_character(),
##   favorite_count = col_integer(),
##   id_str = col_double(),
##   in_reply_to_user_id_str = col_double(),
##   is_retweet = col_character(),
##   retweet_count = col_integer(),
##   source = col_character(),
##   text = col_character()
## )</code></pre>
<pre><code>## Warning in rbind(names(probs), probs_f): number of columns of result is not
## a multiple of vector length (arg 1)</code></pre>
<pre><code>## Warning: 4 parsing failures.
## row # A tibble: 4 x 5 col     row col   expected  actual    file                                     expected   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;                                    actual 1   653 &lt;NA&gt;  8 columns 1 columns &#39;Sentiment_Analysis_files/trump_tweets.… file 2   777 &lt;NA&gt;  8 columns 1 columns &#39;Sentiment_Analysis_files/trump_tweets.… row 3   801 &lt;NA&gt;  8 columns 1 columns &#39;Sentiment_Analysis_files/trump_tweets.… col 4   802 &lt;NA&gt;  8 columns 1 columns &#39;Sentiment_Analysis_files/trump_tweets.…</code></pre>
<pre class="r"><code>trump_sentiment &lt;- get_sentiment(trump_df$text)</code></pre>
<p>And now we join each sentiment score with the corresponding date of the tweet, to obtain a simple tibble containing dates and sentiment scores for each tweet.</p>
<pre class="r"><code>trump_df$sentiment &lt;- trump_sentiment</code></pre>
<p>And some quick summary statistics of the sentiment scores, just so we can get a feel for its range before plotting:</p>
<pre class="r"><code>mean(trump_df$sentiment)</code></pre>
<pre><code>## [1] 0.4753806</code></pre>
<pre class="r"><code>median(trump_df$sentiment)</code></pre>
<pre><code>## [1] 0.5</code></pre>
<pre class="r"><code>min(trump_df$sentiment)</code></pre>
<pre><code>## [1] -8.3</code></pre>
<pre class="r"><code>max(trump_df$sentiment)</code></pre>
<pre><code>## [1] 8</code></pre>
<pre class="r"><code># No built-in mode function in R :/
my_mode &lt;- function(x) {
  ux &lt;- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
my_mode(trump_df$sentiment)</code></pre>
<pre><code>## [1] 0</code></pre>
<p>And a quick scatterplot where the points are evenly spaced (i.e., plotted by order rather than actual date), which we should be careful not to over-interpret, but which we can get some initial impressions from. For example, it looks at first glance like Trump becomes more “emotionally volatile” as time goes on.</p>
<pre class="r"><code>plot(trump_sentiment)</code></pre>
<p><img src="07_Sentiment_Analysis_files/figure-html/plot-trump-1.png" width="672" /></p>
<p>Now the actual time plot. For this we just need to convert the date column (which is currently just in string format) into actual R date objects, using <code>as.Date()</code>:</p>
<pre class="r"><code>trump_df$r_date &lt;- as.Date(trump_df$created_at)</code></pre>
<pre class="r"><code>p &lt;- ggplot(trump_df, aes(r_date, sentiment)) + geom_line() + theme(legend.position = &quot;bottom&quot;)
p</code></pre>
<pre><code>## Warning: Removed 4 rows containing missing values (geom_path).</code></pre>
<p><img src="07_Sentiment_Analysis_files/figure-html/plot-date-1.png" width="672" /></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
