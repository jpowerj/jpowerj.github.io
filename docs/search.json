[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jeff Jacobs",
    "section": "",
    "text": "Hi, I‚Äôm Jeff Jacobs! I am an Assistant Teaching Professor of Data Science and Analytics at Georgetown University.\nI post things here when my brain becomes obsessed with something and needs to get to the bottom of it (since otherwise I annoy friends and family with these things for days on end üòú).\nIf you are one of my students, however, you may be looking for my DSAN Resources page, where I post things that are relevant to Georgetown DSAN students. Otherwise, you can find more on my academic homepage!"
  },
  {
    "objectID": "posts/dc-segregation/index.html",
    "href": "posts/dc-segregation/index.html",
    "title": "Visualizing Segregation in DC",
    "section": "",
    "text": "About ten years ago, Pew Research released an incredible set of maps visualizing how extreme segregation is in DC, race-wise as well as socioeconomic. A screenshot from this old set of visualizations shows what they used to look like:\nUnfortunately, all of these visualizations used MapBox, which seems to just totally not exist anymore (at least, these particular maps are long gone), so that when you try to view these visualizations on Pew‚Äôs website nowadays, you just get a blank page.\nSo, in this document, I recreate the above maps, using open-source libraries in Python to (hopefully) allow interactive visualization of this important information that will last longer than the previous versions in MapBox‚Äôs proprietary format!"
  },
  {
    "objectID": "posts/dc-segregation/index.html#data-overview",
    "href": "posts/dc-segregation/index.html#data-overview",
    "title": "Visualizing Segregation in DC",
    "section": "Data Overview",
    "text": "Data Overview\nThe data behind these maps is somewhat hard to find, but in a strange way that is the opposite of most hard-to-find data cases: here there are so many different data sources for income across the ‚ÄúDC Metro Area‚Äù (the definition of this region, itself, being subject to different interpretations by different data sources), that I ran into the following tradeoff at the start:\n\nIf we want data for just the District of Columbia itself, we can obtain very easy-to-use data directly from the DC government‚Äôs data portal, which is ready for immediate use in the sense that we can plug it into a mapping app and see the data without any need to tweak any settings! Clicking that link, for example, will show a preview of the map directly within the GitHub page! While the GitHub preview won‚Äôt show the income data for each tract, this geojson.io link (with the URL just pointing to that GitHub page) will!\nSimilarly, if we want data for just Maryland or just Virginia, we could obtain fairly easy-to-use geoJSON files from these states‚Äô data portals\nBut, if we want data for the DC Metro Area, allowing apples-to-apples comparisons between (for example) census tracts within DC and in the Maryland suburbs, then we run into a bit of an issue since the relevant US Census data is far less ready-for-use in its raw form."
  },
  {
    "objectID": "posts/dc-segregation/index.html#ipums-data-median-income-by-census-tract",
    "href": "posts/dc-segregation/index.html#ipums-data-median-income-by-census-tract",
    "title": "Visualizing Segregation in DC",
    "section": "IPUMS Data: Median Income by Census Tract",
    "text": "IPUMS Data: Median Income by Census Tract\nFirst we load the data, which contains median household income for all census tracts in the US:\n\nimport pandas as pd\nipums_df = pd.read_csv(\"assets/nhgis0001_ds254_20215_tract.csv\", encoding_errors='ignore')\nipums_df.head()\n\n\n\n\n\n\n\n\nGISJOIN\nYEAR\nSTUSAB\nREGIONA\nDIVISIONA\nSTATE\nSTATEA\nCOUNTY\nCOUNTYA\nCOUSUBA\n...\nPCI\nPUMAA\nGEO_ID\nBTTRA\nBTBGA\nTL_GEO_ID\nNAME_E\nAOQIE001\nNAME_M\nAOQIM001\n\n\n\n\n0\nG0100010020100\n2017-2021\nAL\nNaN\nNaN\nAlabama\n1\nAutauga County\n1\nNaN\n...\nNaN\nNaN\n1400000US01001020100\nNaN\nNaN\n1001020100\nCensus Tract 201, Autauga County, Alabama\n57399.0\nCensus Tract 201, Autauga County, Alabama\n10706.0\n\n\n1\nG0100010020200\n2017-2021\nAL\nNaN\nNaN\nAlabama\n1\nAutauga County\n1\nNaN\n...\nNaN\nNaN\n1400000US01001020200\nNaN\nNaN\n1001020200\nCensus Tract 202, Autauga County, Alabama\n52176.0\nCensus Tract 202, Autauga County, Alabama\n5849.0\n\n\n2\nG0100010020300\n2017-2021\nAL\nNaN\nNaN\nAlabama\n1\nAutauga County\n1\nNaN\n...\nNaN\nNaN\n1400000US01001020300\nNaN\nNaN\n1001020300\nCensus Tract 203, Autauga County, Alabama\n63704.0\nCensus Tract 203, Autauga County, Alabama\n11304.0\n\n\n3\nG0100010020400\n2017-2021\nAL\nNaN\nNaN\nAlabama\n1\nAutauga County\n1\nNaN\n...\nNaN\nNaN\n1400000US01001020400\nNaN\nNaN\n1001020400\nCensus Tract 204, Autauga County, Alabama\n70000.0\nCensus Tract 204, Autauga County, Alabama\n12155.0\n\n\n4\nG0100010020501\n2017-2021\nAL\nNaN\nNaN\nAlabama\n1\nAutauga County\n1\nNaN\n...\nNaN\nNaN\n1400000US01001020501\nNaN\nNaN\n1001020501\nCensus Tract 205.01, Autauga County, Alabama\n60917.0\nCensus Tract 205.01, Autauga County, Alabama\n29232.0\n\n\n\n\n5 rows √ó 45 columns\n\n\n\nWe can get a sense of how many Census Tracts there are across different states, before we restrict ourselves to just the DMV:\n\n# Here you can uncomment the following to install itables,\n# if it is not already installed in your environment!\n# We just use this to display nice HTML tables with pagination,\n# so it's optional and you don't need to worry if it\n# fails to install for whatever reason.\n#!pip install itables\n\n\nfrom itables import show\ntract_counts = ipums_df['STUSAB'].value_counts().to_frame().reset_index()\nshow(tract_counts)\n\n\n\n\n\n\n\n\nSTUSAB\ncount\n\n\n\n\nLoading... (need help?)\n\n\n\n\n\n\n\n\n\n\n\nBut now we can restrict our analysis to just DC, Maryland, and Virginia:\n\nstates_to_include = [\n    'District of Columbia',\n    'Maryland',\n    'Virginia'\n]\ndmv_df = ipums_df[ipums_df['STATE'].isin(states_to_include)].copy()\n\nAnd we can look at the 153 unique values that are listed in the ‚ÄúCounty‚Äù field for these states, where you‚Äôll see that this corresponds not only to ‚Äúcounties‚Äù in the standard colloquial sense but also to areas that have not been incorporated into any counties: places like Alexandria city:\n\ncounty_counts = dmv_df['COUNTY'].value_counts(dropna=False)\nshow(county_counts)\n\n\n\n\n\n\n\n\n\ncount\n\n\nCOUNTY\n\n\n\n\n\nLoading... (need help?)\n\n\n\n\n\n\n\n\n\n\n\nGoing through these unique values, I select the areas that seemed to be included in Pew‚Äôs ‚ÄúDC Metro Area‚Äù map:\n\ncounties = [\n    'Fairfax County', # 274 tracts\n    'Montgomery County', # 255 tracts\n    \"Prince George's County\", # 214 tracts\n    'District of Columbia', # 206 tracts\n    'Arlington County', # 71 tracts\n    'Alexandria city', # 48 tracts\n    'Fairfax city', # 5 tracts\n    'Falls Church city', # 3 tracts\n]\ndmv_df = dmv_df[dmv_df['COUNTY'].isin(counties)].copy()\n\nAnd now, since we‚Äôre about to merge this data with the shapefiles for Maryland, DC, and Virginia, which have a GEOID field of type string, we‚Äôll need to create a string version of the TL_GEO_ID variable from IPUMS, for merging:\n\n# String version for merging\ndmv_df['TL_GEO_ID_str'] = dmv_df['TL_GEO_ID'].apply(str)"
  },
  {
    "objectID": "posts/dc-segregation/index.html#tiger-shapefiles-for-dc-maryland-and-virginia",
    "href": "posts/dc-segregation/index.html#tiger-shapefiles-for-dc-maryland-and-virginia",
    "title": "Visualizing Segregation in DC",
    "section": "TIGER Shapefiles for DC, Maryland, and Virginia",
    "text": "TIGER Shapefiles for DC, Maryland, and Virginia\nNext we‚Äôll load the TIGER shapefiles provided by the Census website, for DC (FIPS code 11), Maryland (FIPS code 24), and Virginia (FIPS code 51).\nHere we use the amazing GeoPandas library, which essentially lets us keep using Pandas as we‚Äôve been using it, but also maintains a GIS representation of the data ‚Äúunder the hood‚Äù, so that when we‚Äôre ready to plot our data we can plug the GeoDataFrame object into (for example) Plotly or any other data visualization library that supports mapping!\n\n# Uncomment the following to install geopandas, if it is\n# not already installed in your environment!\n#!pip install geopandas\n\n\nimport geopandas as gpd\n# Shapefiles\ndc_shape_df = gpd.read_file(\"assets/tl_2021_11_tract/tl_2021_11_tract.shp\")\nmd_shape_df = gpd.read_file(\"assets/tl_2021_24_tract/tl_2021_24_tract.shp\")\nva_shape_df = gpd.read_file(\"assets/tl_2021_51_tract/tl_2021_51_tract.shp\")\ndmv_shape_df = pd.concat([dc_shape_df,md_shape_df,va_shape_df], ignore_index=True)\n\nNow, since our original dmv_df and the GeoPandas-managed dmv_shape_df both have GEO_ID variables (with slightly different names), we can merge them into a single DataFrame and then tell GeoPandas to track all of this information!\n\ngeo_df_pd = pd.merge(dmv_df, dmv_shape_df, left_on='TL_GEO_ID_str', right_on='GEOID', how='left')\ngeo_df = gpd.GeoDataFrame(geo_df_pd)\ngeo_df.set_index('GEOID', inplace=True)\n\nAnd now, finally, we can make use of Plotly‚Äôs Cloropethmapbox object to create a Cloropeth map of the different income levels:\n\n# Uncomment the following to install Plotly, if it is not already\n# installed on your machine!\n#!pip install plotly\n\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\nmedian_income_var = \"AOQIE001\"\n# Capitol Building\n#capitol_lat = 38.889805\n#capitol_lon = -77.009056\n# White House\n#center_lat = 38.8977\n#center_lon = -77.0365\n# Scott Statue\ncenter_lat = 38.907278946266466\ncenter_lon = -77.03651807332851\n\nincome_fig = px.choropleth_mapbox(\n    geo_df,\n    geojson=geo_df.geometry,\n    locations=geo_df.index,\n    #z=geo_df[median_income_var],\n    color=median_income_var,\n    #autocolorscale=True,\n    opacity=0.7,\n    mapbox_style='carto-positron',\n    zoom = 10.4,\n    center = {\n        \"lat\": center_lat,\n        \"lon\": center_lon,\n    },\n    # width=800,\n    # height=800\n)\nincome_fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nincome_fig.show()\n\n\n                                                \n\n\nNotice anything? ‚Ä¶I feel like the raw median income distribution pretty much tells the whole story, but if we want to fully recreate the Pew maps, we could collapse these income levels down into (low, medium, high) using the methodology from the report‚Äôs appendix to produce a map of categorical income levels. For 2021, the most recent year for which IPUMS had the 5-year ACS data, the median income for the DC metro area was $110,355 (for comparison, the national median household income was $70,784), so that (letting \\(M\\) represent this metro-area median)\n\nThe cutoff for low-income (using Pew‚Äôs methodology) is \\(\\frac{2}{3}\\cdot M\\) = $73,570\nThe cutoff for high-income (again using Pew‚Äôs methodology) is \\(2M\\) = $220,710\n\n\nmedian_income_var = \"AOQIE001\"\n# Capitol Building\n#capitol_lat = 38.889805\n#capitol_lon = -77.009056\n# White House\ncenter_lat = 38.8977\ncenter_lon = -77.0365\n\n# Here we'll drop NA, since Plotly doesn't handle\n# NA values as well as NaN values\ngeo_df_nona = geo_df[~pd.isna(geo_df[median_income_var])].copy()\n# Cutpoints\n#natl_median = 70000\nmetro_median = 110355\nlow_cutoff = (2/3) * metro_median\nhigh_cutoff = 2 * metro_median\ndef get_income_level(income):\n    # If NA, we want to keep its category as NA\n    if pd.isna(income):\n        return pd.NA\n    if income &lt; low_cutoff:\n        return \"Low\"\n    if income &gt; high_cutoff:\n        return \"High\"\n    return \"Medium\"\ngeo_df_nona['income_level'] = geo_df_nona[median_income_var].apply(get_income_level)\nlevel_fig = px.choropleth_mapbox(geo_df_nona,\n  geojson=geo_df_nona.geometry,\n  color=\"income_level\",\n  locations=geo_df_nona.index,\n  #featureidkey=\"properties.district\",\n  center={\"lat\": center_lat, \"lon\": center_lon},\n  mapbox_style=\"carto-positron\",\n  hover_data=[median_income_var],\n  zoom=10,\n  color_discrete_map={\n    'High': 'green',\n    'Medium': 'lightgrey',\n    'Low': 'red'\n  }\n)\nlevel_fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nlevel_fig.show()\n\n\n                                                \n\n\nAnd voila! The pattern looks‚Ä¶ even more bleak in 2021 than it did in 2012 üòî"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jeff's Rants",
    "section": "",
    "text": "Visualizing Segregation in DC\n\n\n\n\n\n\n\nUrban Studies\n\n\nGIS\n\n\nSegregation\n\n\nInequality\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2023\n\n\nJeff Jacobs\n\n\n\n\n\n\nNo matching items"
  }
]